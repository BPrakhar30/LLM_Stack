{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API Key\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process image to generate descriptions and saving them in a JSON format\n",
    "def process_image(image_path):\n",
    "    base64_image = encode_image(image_path)\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4-vision-preview\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        # \"text\": \"Describe the main subjects and objects in this image, including any context or scene details, recognize any text or symbols, and identify emotions or actions depicted. Remember to use only keywords and not the filler words accodrding to the grammar \"\n",
    "                        # \"text\": \"\"\"\n",
    "                        #         As an image description generator, your task is to provide concise and accurate descriptions of images within a 20-30 word limit. Follow these guidelines to ensure your descriptions are both informative and succinct:\n",
    "                                \n",
    "                        #         1. List any people or prominent subjects, noting their positions and actions. If the image is crowded, prioritize the most central or striking figures.\n",
    "                        #         2. Briefly describe significant background elements. Choose details that frame the context of the image effectively.\n",
    "                        #         3. Mention any clear text, symbols, or logos, which are crucial for understanding the image's context or intention.\n",
    "                        #         4. Only comment on the mood or themes like happiness, freedom, success.....etc., if these are directly observable from expressions or actions.\n",
    "                        #         5. Include only what is clearly visible. Do not infer or assume details not explicitly shown in the image.\n",
    "                        #         6. Maintain a neutral tone, avoiding subjective interpretations or emotional language unless directly relevant to the described actions or expressions.\n",
    "                        #         Most importantly your description should balance brevity with informativeness, capturing the essence of the image while adhering to the word limit.\n",
    "                        #         \"\"\"\n",
    "                        \"text\": \"\"\"\n",
    "                                As an image tags generator, your task is to provide concise and accurate tags of images. Follow these guidelines to ensure your tags are both informative and succinct:\n",
    "                                \n",
    "                                1. List any people or prominent subjects, noting their positions and actions. If the image is crowded, prioritize the most central or striking figures.\n",
    "                                2. Give tags significant background elements. Choose details that frame the context of the image effectively.\n",
    "                                3. Give tags for any clear text, symbols, or logos, which are crucial for understanding the image's context or intention.\n",
    "                                4. Only give tags on the mood or themes like happiness, freedom, success.....etc., if these are directly observable from expressions or actions.\n",
    "                                5. Include only what is clearly visible. Do not infer or assume details not explicitly shown in the image.\n",
    "                                6. Maintain a neutral tone, avoiding subjective interpretations or emotional language unless directly relevant to the described actions or expressions.\n",
    "                                Most importantly your tags should balance brevity with informativeness, capturing the essence of the image while adhering to the condition that tags must be separated by a space(“ ”) and for each tag include a few similar words that can be used inplace of the oriignal tag\n",
    "                                \"\"\"\n",
    "        \n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 300\n",
    "    }\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    return response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved output for 001121e5-406a-4c02-9d49-96cacb33bc78.jpg\n",
      "Processed and saved output for 002_112_001.jpg\n",
      "Processed and saved output for 002_121_001.jpg\n",
      "Processed and saved output for 002_541_001.jpg\n",
      "Processed and saved output for 002_579_001.jpg\n",
      "Processed and saved output for 003afd84-635e-4a02-bf08-8c3a6be2c8f6.jpg\n",
      "Processed and saved output for 004d83ee-e38c-4ad1-8d3d-8d1595aeb57d.jpg\n",
      "Processed and saved output for 00be5180-9c0b-49e5-aec9-098633c8ab2b.jpg\n",
      "Processed and saved output for 027_029_001.jpg\n",
      "Processed and saved output for 035_320_001.jpg\n",
      "Processed and saved output for 035_321_001.jpg\n",
      "Processed and saved output for 04f77e3d-4d90-47f7-8d31-ada88fa53788.jpg\n",
      "Processed and saved output for 071_018_002.jpg\n",
      "Processed and saved output for 071_018_003.jpg\n",
      "Processed and saved output for 14.jpg\n",
      "Processed and saved output for 1408c1b2-c488-4924-afde-0d8835f1070e.jpg\n",
      "Processed and saved output for 15.jpg\n",
      "Processed and saved output for 16.jpg\n",
      "Processed and saved output for 18.jpg\n",
      "Processed and saved output for 2a42714d-2e2d-4f1f-99c8-1d9bfb2a716e.jpg\n",
      "Processed and saved output for 2a9683a8-5f03-44d1-a6c9-dd07450db601.jpg\n",
      "Processed and saved output for 2b2d05c7-ddb9-4baa-a1dd-71ff28e57ea0.jpg\n",
      "Processed and saved output for 2bfa5428-0e8d-435d-8753-a1e8d30a4bba.jpg\n",
      "Processed and saved output for 2bfdd8ec-160d-427b-9a92-a4eddb74374d.jpg\n",
      "Processed and saved output for 2c355850-fbf5-45ed-aa61-01a5bebb40b7.jpg\n",
      "Processed and saved output for 2c57e8fa-fb06-4721-be00-4dc923ab45c5.jpg\n",
      "Processed and saved output for 2d7ada3d-9407-4056-8151-7334cea11818.jpg\n",
      "Processed and saved output for 33ae97a6-62fc-405f-b917-07814c0c6629.jpg\n",
      "Processed and saved output for 4.jpg\n",
      "Processed and saved output for 4a29e13b-696b-4787-8ff2-6803b836fae7.jpg\n",
      "Processed and saved output for 4aa962a9-fc40-465a-803b-bd3561d006eb.jpg\n",
      "Processed and saved output for 4bc21050-49a8-4c26-91d0-d96d0125c62f.jpg\n",
      "Processed and saved output for 4cda4f52-bfd2-4a15-856a-d396a06610d9.jpg\n",
      "Processed and saved output for 4cf493f7-4886-4271-8e8e-3c347a0ee2b4.jpg\n",
      "Processed and saved output for 4d61605f-3fae-4eec-a4bc-ad65534b5847.jpg\n",
      "Processed and saved output for 4ee0c430-a5d6-43ae-b216-8a05c1574c11.jpg\n",
      "Processed and saved output for CCTV_13.png\n",
      "Processed and saved output for CCTV_14.png\n"
     ]
    }
   ],
   "source": [
    "# Directory containing images\n",
    "directory_path = r\"path_to_the_image_directory\"\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.lower().endswith(('.png', '.jpg')):\n",
    "        full_path = os.path.join(directory_path, filename)\n",
    "        output = process_image(full_path)\n",
    "        \n",
    "        # Save the output in a JSON file\n",
    "        output_filename = os.path.splitext(filename)[0] + '.json'\n",
    "        output_path = os.path.join(directory_path, output_filename)\n",
    "        with open(output_path, 'w') as json_file:\n",
    "            json.dump(output, json_file, indent=4)\n",
    "\n",
    "        print(f\"Processed and saved output for {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
