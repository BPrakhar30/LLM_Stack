{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Engineering Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-jado\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain import FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_template='''I want you to act as a acting financial advisor for people. In an easy way, explain the basics of {financial_concept} in 3 sentences.'''\n",
    "\n",
    "prompt=PromptTemplate( input_variables=['financial_concept'], template=demo_template)\n",
    "\n",
    "# prompt.format(financial_concept='income tax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=OpenAI(temperature=0.8, max_tokens=140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. GDP, or Gross Domestic Product, is a measure of the total value of all goods and services produced within a country in a given time period, usually a year.\n",
      "2. It is an important indicator of a country's economic health and can help determine the overall growth and productivity of an economy.\n",
      "3. A higher GDP generally signifies a stronger economy, while a lower GDP may indicate a weaker economy with potential for improvement.\n"
     ]
    }
   ],
   "source": [
    "chain1=LLMChain(llm=llm,prompt=prompt)\n",
    "response = chain1.run({'financial_concept': 'GDP'})\n",
    "\n",
    "# Print the response\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In an easy way translate the following sentence 'How are you' into Hindi\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Language Translation\n",
    "\n",
    "template='''In an easy way translate the following sentence '{Sentence}' into {Target_Language}'''\n",
    "language_prompt = PromptTemplate(input_variables=[\"Sentence\",'Target_Language'],template=template)\n",
    "language_prompt.format(Sentence=\"How are you\",Target_Language='Hindi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prakh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Sentence': 'Hello How are you',\n",
       " 'Target_Language': 'Hindi',\n",
       " 'text': '\\n\\nनमस्ते आप कैसे हो? (Namaste aap kaise ho?)'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2=LLMChain(llm=llm,prompt=language_prompt)\n",
    "\n",
    "chain2({'Sentence':\"Hello How are you\",'Target_Language':'Hindi'})   # can't use chain.run as # of parameters are >1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create the list of few shot examples.\n",
    "examples = [\n",
    "    {\"word\": \"happy\", \"antonym\": \"sad\"},\n",
    "    {\"word\": \"tall\", \"antonym\": \"short\"},\n",
    "]\n",
    "\n",
    "# Next, we specify the template to format the examples we have provided.\n",
    "# We use the `PromptTemplate` class for this.\n",
    "example_formatter_template = \"\"\"Word: {word} Antonym: {antonym}\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(input_variables=[\"word\", \"antonym\"],template=example_formatter_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the `FewShotPromptTemplate` object\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(examples=examples, example_prompt=example_prompt, prefix=\"Give the antonym of every input\\n\", suffix=\"Word: {input}\\nAntonym: \", input_variables=[\"input\"], example_separator=\"\\n\")\n",
    "    \n",
    "    # These are the examples we want to insert into the prompt.\n",
    "    \n",
    "    # This is how we want to format the examples when we insert them into the prompt.\n",
    "    \n",
    "    # The prefix is some text that goes before the examples in the prompt. Usually, this consists of intructions.\n",
    "    \n",
    "    # The suffix is some text that goes after the examples in the prompt. Usually, this is where the user input will go\n",
    "    \n",
    "    # The input variables are the variables that the overall prompt expects.\n",
    "    \n",
    "    # The example_separator is the string we will use to join the prefix, examples, and suffix together with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Word: happy Antonym: sad\n",
      "Word: tall Antonym: short\n",
      "Word: big\n",
      "Antonym: \n"
     ]
    }
   ],
   "source": [
    "print(few_shot_prompt.format(input='big'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'big', 'text': 'small'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain=LLMChain(llm=llm,prompt=few_shot_prompt)\n",
    "chain({'input':\"big\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
